{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa8764e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "['199655', '130518', '209228', '214019', '131722', '365343', '203418', '115017', '155938', '601127', '130114', '158035', '116726', '467351', '585256', '158136', '385046', '191336', '536647', '187345', '901139', '360030', '146129', '783462', '212419', '562345', '191033', '197348', '732243', '134829', '757764', '263436', '899885', '814649', '214524', '186949', '145834', '789373', '140117', '239136', '169040', '725751', '181636', '177645', '134627', '318637', '871762', '251833', '177746', '192641', '765864', '389357', '178142', '200614', '943862', '905147', '249947', '638049', '135124', '162935', '193845', '191841', '406836', '381038', '111514', '395756', '973770', '146432', '100610', '125525', '878776', '150423', '581450', '412528', '167036', '330324', '393247', '178243', '156334', '951457', '680957', '617748', '182739', '115825', '397760', '671855', '283543', '547046', '995174', '380036', '706040', '159239', '146735', '128935', '164636', '966975', '196144', '173334', '901442', '108323', '525541', '771354', '204521', '201515', '320826', '131217', '200210', '185442', '942658', '833249', '644246', '550439', '175237', '826353', '690152', '146937', '926862', '257845', '971160', '654552', '181232', '198653', '818859', '171633', '541943', '111312', '200311', '246133', '157336', '572045', '627549', '148133', '102816', '878877', '132118', '195041', '221319', '859671', '164131', '172130', '401422', '192439', '180533', '102311', '144226', '105923', '552241', '898176', '233326', '910241', '573249', '178647', '958976', '177140', '118225', '861456', '205220', '429040', '126426', '751550', '167440', '463040', '724446', '346137', '770352', '137128', '436845', '165436', '169747', '927359', '109123', '182436', '114823', '176542', '872764', '352738', '782561', '825048', '104416']\n",
      "151\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import shutil\n",
    "#f = h5py.File('/Users/ribeiroadmin/Downloads/100610.labels.hdf5', 'r')# %%\n",
    "#left = f['lh']['visual_area']\n",
    "#left = np.array(left)\n",
    "\n",
    "\n",
    "label_files = []\n",
    "subjects = []\n",
    "#\n",
    "#!!!\n",
    "#\n",
    "path_to_files = \"/BULK/LABDATA/openneuro/nyu4christian/HCP\"\n",
    "anatomists = [\"A1\", \"A2\", \"A3\", \"A4\"]\n",
    "hemisphere = ['lh', 'rh']\n",
    "\n",
    "\n",
    "# create an array with all the file names containing \".labels.hdf5\"\n",
    "path_to_sub = (\"{path_to_files}/{anatom}\").format(path_to_files=path_to_files, anatom=anatomists[0])\n",
    "for files in os.listdir(path_to_sub):\n",
    "    if files.endswith(\"labels.hdf5\"):\n",
    "        # append all files with \".labels.hdf5\" from A1\n",
    "        label_files.append(files)\n",
    "        # if they are not in one of the other anatomists, the file will be removed\n",
    "        for anatom in anatomists:\n",
    "            path_to_file = (\"{path_to_files}/{anatom}/{files}\").format(path_to_files=path_to_files, anatom=anatom, files=files)\n",
    "            if not os.path.isfile(path_to_file):\n",
    "                if files in label_files:\n",
    "                    label_files.remove(files)\n",
    "\n",
    "\n",
    "# create a folder for all subjects an their files containing the maps from every anatomist\n",
    "new_dir = (\"{path_to_files}/subjects\").format(path_to_files=path_to_files)\n",
    "if not os.path.exists(new_dir):\n",
    "    os.makedirs(new_dir)\n",
    "\n",
    "# create a new array to have the subject names without the whole file name\n",
    "for files in label_files:\n",
    "    sub = files[:-12]\n",
    "    subjects.append(sub)\n",
    "\n",
    "print(len(subjects))\n",
    "print(subjects)\n",
    "\n",
    "# save all subjects where all data is correct\n",
    "valid_subjects = []\n",
    "maps = {}\n",
    "for sub in subjects:\n",
    "    # boolean to see if it worked\n",
    "    is_valid = True\n",
    "\n",
    "    \n",
    "    # create a folder for every subject\n",
    "    SUBJECTS_DIR = (\"{new_dir}/{sub}\").format(new_dir=new_dir, sub=sub)\n",
    "    if not os.path.exists(SUBJECTS_DIR):\n",
    "        os.makedirs(SUBJECTS_DIR)\n",
    "    \n",
    "\n",
    "    # create the maps from \".labels.hdf5\" files\n",
    "    for anatom in anatomists:\n",
    "        path = (\"{path_to_files}/{anatom}/{sub}.labels.hdf5\").format(path_to_files=path_to_files, anatom=anatom, sub=sub)\n",
    "        f = h5py.File(path, 'r')# %%\n",
    "        for hemi in hemisphere:\n",
    "            # put all maps into the dictionary maps and save all maps in the SUBJECTS_DIR\n",
    "            try:\n",
    "                with h5py.File(path, 'r') as f:\n",
    "                    # if 'lh' or 'visual_area' is not in the file, the error will be saved and the files with the subject and the subject itself will be removed\n",
    "                    if hemi not in f:\n",
    "                        #print(f\"'lh' is missing in: {path}\")\n",
    "                        txt = f\"{path_to_files}/log.txt\"\n",
    "                        with open(txt, \"a\") as text:\n",
    "                            text.write(f\"{hemi} is missing in: {path}\\n\")\n",
    "                        is_valid = False\n",
    "                        break\n",
    "                    if 'visual_area' not in f[hemi]:\n",
    "                        #print(f\"'visual_area' is missing in: {path}\")\n",
    "                        txt = f\"{path_to_files}/log.txt\"\n",
    "                        with open(txt, \"a\") as text:\n",
    "                            text.write(f\"'visual_area' is missing in: {path}\\n\")\n",
    "                        is_valid = False\n",
    "                        break\n",
    "\n",
    "                            \n",
    "                    # load the maps\n",
    "                    curr_map = f[hemi]['visual_area']\n",
    "                    curr_map = np.array(curr_map)\n",
    "                    \n",
    "                    # create the dictionary with the maps\n",
    "                    if sub not in maps:\n",
    "                        maps[sub] = {anatom: {hemi: [] for hemi in hemisphere} for anatom in anatomists}\n",
    "                    maps[sub][anatom][hemi] = curr_map\n",
    "                    #print(maps[sub][anatom][hemi])\n",
    "                    path_to_save = (f\"{SUBJECTS_DIR}/{anatom}.{hemi}.visual_area.gii\")\n",
    "                    gii_data = nib.gifti.GiftiDataArray(data=curr_map)\n",
    "                    gii_img = nib.gifti.GiftiImage(darrays=[gii_data])\n",
    "                    nib.save(gii_img, path_to_save)\n",
    "\n",
    "            # if it cannot open the file it will be reported\n",
    "            except Exception as e:\n",
    "                #print(f\"Can't open file {path}: {e}\")\n",
    "                txt = f\"{path_to_files}/log.txt\"\n",
    "                with open(txt, \"a\") as text:\n",
    "                    text.write(f\"Can't open file {path}\\n\")\n",
    "                is_valid = False\n",
    "                break\n",
    "        if not is_valid:\n",
    "            break\n",
    "    if not is_valid:\n",
    "        if os.path.exists(SUBJECTS_DIR):\n",
    "            shutil.rmtree(SUBJECTS_DIR)\n",
    "        if sub in maps:\n",
    "            del maps[sub]\n",
    "    else:\n",
    "        valid_subjects.append(sub)\n",
    "subjects = valid_subjects\n",
    "\n",
    "print(len(subjects))\n",
    "print(len(maps))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuropythy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
